{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "JMFgvj4NL4F4"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#  SVM Classifier\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xcBK9oXFOmXA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "SVM or Support Vector Machine is a supervised learning algorithm. SVM's are used for both classification and regression. SVM works by finding an optimal hyperplane which categorizes the examples. For N number of features we need N-1 Hyperplanes. Hyperplanes are those decision boundaries that help us classify the data points. Any point lying on either side of the hyperplane is given the class lablel accordingly. \n",
        "\n",
        "SVM is effective when we have to deal high dimensional spaces even if the number of dimensions are greater than the number of samples.\n",
        "\n",
        "You can see how the SVM works and creates a hyperplanes in the figure below.\n",
        "\n",
        "![SVM](https://github.com/bhragu/Alset/blob/master/img/SVM.png?raw=true)\n",
        "\n",
        "The SVM algorithm is implemented in sklearn library and here is a simple sample of using that:\n",
        "\n",
        "    classifier = SVC(kernel = 'linear', random_state = 10)\n",
        "    classifier.fit(x,y)\n",
        "    \n",
        "You can also find more about the classifier parametrs [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
        "\n",
        "In the given problem you will be using a linear kernel which uses a linear function to create the hyperplane.\n",
        "\n",
        "---\n",
        "\n",
        "Now it's your turn!\n",
        "\n",
        "Change the svm_classifier_function which takes in an a training set (x,y) and return a decision tree classifier based on the input. Don't forget normalization!"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zbJXF-sQL4HI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#problem\n",
        "\n",
        "def svm_classifier_function(x, y):\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "#   x is data and y is the target\n",
        "#   use standard scalar to normalise the data \n",
        "#   Build the classfier using SVC\n",
        "   return #the classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Kns76xf8L4Hm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tests \n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "df = datasets.load_iris()\n",
        "x = df.data[:, :2]\n",
        "y = df.target\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=5685)\n",
        "model = svm_classifier_function(x_train, y_train)\n",
        "sc = StandardScaler()\n",
        "x_test = sc.fit_transform(x_test)\n",
        "prediction = model.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, prediction)\n",
        "\n",
        "#the plot begins \n",
        "from matplotlib.colors import ListedColormap\n",
        "x = sc.fit_transform(x)\n",
        "x_set, y_set = x_train, y_train\n",
        "x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
        "y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "z = z.reshape(xx.shape)\n",
        "\n",
        "color_list_light = ['red', 'yellow','green']\n",
        "color_list_bold = ['red', 'yellow','green']\n",
        "custom_cmap2 = ListedColormap(color_list_light)\n",
        "custom_cmap1 = ListedColormap(color_list_bold)\n",
        "plt.contourf(xx, yy, z, alpha=0.1,cmap=custom_cmap2)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y,cmap=custom_cmap1,\n",
        "                              s=20, edgecolor='black')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ai_8oG9jbhr0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert accuracy >.50, 'Try normalising your data to improve the accuracy of your model. '"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}