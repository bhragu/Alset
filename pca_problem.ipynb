{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pca_problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5-ZxMjkDy2Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#PCA\n"
      ]
    },
    {
      "metadata": {
        "id": "FC8arv79KYtw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Principal component analysis is a fast and flexible unsupervised method for dimensionality reduction in data, but it can also be useful as a tool for visualization, for noise filtering, for feature extraction and engineering, and much more. Using PCA for dimensionality reduction involves zeroing out one or more of the smallest principal components, resulting in a lower-dimensional projection of the data that preserves the maximal data variance. There are some methodes in sklearn library for implementing PCA in python.\n",
        "\n",
        "EXAMPLE 1:\n",
        "\n",
        "\n",
        "    from sklearn.decomposition import PCA\n",
        "    num_of_components = 1\n",
        "    pca = PCA(n_components = num_of_components)\n",
        "    x = pca.fit_transform(x) #run PCA algorithm on x dataframe with 1 components.\n",
        "    \n",
        "---\n",
        "\n",
        "Now is your turn!\n",
        "\n",
        "Change the pca_function to takes in an input x that is a dataframe and run the PCA algorithm with 2 components. Please note that it is very important to normalize the data before running the PCA algorithm. You can run without normailzation and run again after normalization and observe the change.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZT4C2hLTyB7i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#problem\n",
        "#First run without normailzation and run again after normalization and observe the change\n",
        "def pca_function(x):\n",
        "#   from sklearn.preprocessing import StandardScaler\n",
        "#   sc = StandardScaler()\n",
        "#   x= sc.fit_transform(x)\n",
        "#   from sklearn.decomposition import PCA\n",
        "#   Your PCA algorithm with two components.\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XHoIisrPyB8A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Tests \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "import random\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "df = datasets.load_wine()\n",
        "x = df.data\n",
        "y = df.target\n",
        "x = pca_function(x)\n",
        "\n",
        "plt.scatter(x[y == 0, 0], x[y == 0, 1],  c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(x[y == 1, 0], x[y == 1, 1], c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(x[y == 2, 0], x[y == 2, 1],  c = 'green', label = 'Cluster 3')\n",
        "plt.title('PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gagVbfCOyB8L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert x.shape[1]== 2 ,'Dimensions not reduced properly'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}