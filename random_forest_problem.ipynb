{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_forest_problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "r_gORB8a6fnS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Random Forest\n"
      ]
    },
    {
      "metadata": {
        "id": "l6SaKOPd9ATy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Random forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance.\n",
        "\n",
        "The following are the basic steps involved in performing the random forest algorithm:\n",
        "\n",
        "*  Pick N random records from the dataset.\n",
        "*  Build a decision tree based on these N records.\n",
        "*  Choose the number of trees you want in your algorithm and repeat steps 1 and 2.\n",
        "*  In case of a classification problem, each tree in the forest predicts the category to which the new record belongs. Finally, the new record is assigned to the category that wins the majority vote.\n",
        "\n",
        "\n",
        "![alt text](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526467744/voting_dnjweq.jpg)\n",
        "\n",
        "\n",
        "\n",
        "The Random Forest algorithm has implemented in sklearn library and here is a simple sample of using that:\n",
        "\n",
        "    classifier = RandomForestClassifier(n_estimators = 10)\n",
        "    classifier.fit(x,y)\n",
        "    \n",
        "You can also find more about the classifier parametrs [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
        "\n",
        "---\n",
        "\n",
        "Now is your turn!\n",
        "\n",
        "Change the random_forest_classifier_function to takes in an a training set (x,y) and return a decision tree classifier based on the input. Don't forget normalization!\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ft-VLq796hj8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#problem\n",
        "\n",
        "def random_forest_classifier_function(x, y):\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  #Build the classfier and return it\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VM34bW8p6hkb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tests \n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import datasets\n",
        "df = datasets.load_wine()\n",
        "x = df.data[:, 9:11]\n",
        "y = df.target\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=5685)\n",
        "model = random_forest_classifier_function(x_train, y_train)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_test = sc.fit_transform(x_test)\n",
        "\n",
        "prediction = model.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, prediction)\n",
        "\n",
        "#the plot begins \n",
        "x = sc.fit_transform(x)\n",
        "from matplotlib.colors import ListedColormap\n",
        "x_set, y_set = x_train, y_train\n",
        "x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
        "y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "z = z.reshape(xx.shape)\n",
        "\n",
        "color_list_light = ['red', 'green','blue']\n",
        "color_list_bold = ['red', 'green','blue']\n",
        "custom_cmap2 = ListedColormap(color_list_light)\n",
        "custom_cmap1 = ListedColormap(color_list_bold)\n",
        "plt.contourf(xx, yy, z, alpha=0.1,cmap=custom_cmap2)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y,cmap=custom_cmap1,\n",
        "                              s=20, edgecolor='black')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3mgl_p_IuIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert accuracy >.8, 'Failed'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}